import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError
from tensorflow.image import ssim
from PyQt5.QtWidgets import QApplication, QMainWindow, QFileDialog, QPushButton, QVBoxLayout, QWidget, QLabel, QHBoxLayout
from PyQt5.QtGui import QImage, QPixmap
from PyQt5.QtCore import Qt
import time
import threading

# Define your model and its architecture

# Define loss calculation function
def total_loss(y_true, y_pred):
    lambda_mse = 2.5  # Adjust as needed
    lambda_mae = 2.5
    lambda_ssim = 2  # Adjust as needed
    lambda_color = 20  # Adjust the weight as needed

    # Compute MSE loss
    mse = MeanSquaredError()(y_true, y_pred)

    # Compute MAE loss
    mae = MeanAbsoluteError()(y_true, y_pred)

    # Compute SSIM loss
    ssim_loss = 1 - ssim(y_true, y_pred, max_val=1.0)  # max_val should match your image range (e.g., 0-1)

    # Custom color loss based on color histograms
    def color_loss(y_true, y_pred):
        # Convert the images to grayscale
        y_true_gray = tf.image.rgb_to_grayscale(y_true)
        y_pred_gray = tf.image.rgb_to_grayscale(y_pred)
        #Wp mate gg
        # Calculate the MSE between the grayscale images
        color_loss = tf.reduce_mean(tf.square(y_true_gray - y_pred_gray))

        return color_loss

    # Compute color loss
    color = color_loss(y_true, y_pred)

    # Combine losses with weights
    loss = (
        lambda_mse * mse +
        lambda_mae * mae +
        lambda_ssim * ssim_loss +
        lambda_color * color
    )

    return loss

# Load the pre-trained dehazing model
model = tf.keras.models.load_model('model121.h5',custom_objects={'total_loss': total_loss})

# Define a function to preprocess the frame
def preprocess_frame(frame):
    # Convert the frame to RGB
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Resize the frame to (96, 124)
    resized_frame = cv2.resize(rgb_frame, (512, 512))

    # Normalize the frame
    normalized_frame = resized_frame / 255.0

    # Add an extra dimension for batch size
    preprocessed_frame = np.expand_dims(normalized_frame, axis=0)

    return preprocessed_frame

# Define a function to postprocess the frame
def postprocess_frame(frame, original_shape):
    # Resize the frame to the original shape
    resized_frame = cv2.resize(frame, (original_shape[1], original_shape[0]))

    # Convert the frame to BGR
    bgr_frame = cv2.cvtColor(resized_frame, cv2.COLOR_RGB2BGR)

    # Convert the frame to uint8
    final_frame = (bgr_frame * 255.0).astype(np.uint8)

    return final_frame

# Define the main window class
class VideoProcessingApp(QMainWindow):
    def update_video_display(self, frame, label_widget):
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        height, width, channel = frame.shape
        bytes_per_line = 3 * width
        q_image = QImage(frame.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image) 
        label_widget.setPixmap(pixmap.scaled(640, 480, Qt.KeepAspectRatio))
    def __init__(self):
        super().__init__()

        self.setWindowTitle("Video Processing App")
        self.setGeometry(100, 100, 1024, 768)

        self.initUI()
        self.video_processing_thread = None

    def initUI(self):
        self.central_widget = QWidget()
        self.setCentralWidget(self.central_widget)

        self.input_video_label = QLabel("Input Video:")
        self.input_video_display = QLabel()
        self.input_video_display.setAlignment(Qt.AlignCenter)

        self.output_video_label = QLabel("Output Video:")
        self.output_video_display = QLabel()
        self.output_video_display.setAlignment(Qt.AlignCenter)

        self.load_video_button = QPushButton("Load Video")
        self.load_video_button.clicked.connect(self.load_video)

        # Layout setup
        layout = QVBoxLayout()
        layout.addWidget(self.input_video_label)
        layout.addWidget(self.input_video_display)
        layout.addWidget(self.output_video_label)
        layout.addWidget(self.output_video_display)
        layout.addWidget(self.load_video_button)
        self.central_widget.setLayout(layout)

    def load_video(self):
        options = QFileDialog.Options()
        options |= QFileDialog.ReadOnly
        file_name, _ = QFileDialog.getOpenFileName(
            self, "Open Video File", "", "Video Files (*.mp4 *.avi);;All Files (*)", options=options
        )

        if file_name:
            if self.video_processing_thread and self.video_processing_thread.is_alive():
                self.video_processing_thread.join()

            self.video_processing_thread = threading.Thread(target=self.process_video, args=(file_name,))
            self.video_processing_thread.start()

    def process_video(self, file_name):
        input_cap = cv2.VideoCapture(file_name)
        fps = int(input_cap.get(cv2.CAP_PROP_FPS))

        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        width = int(input_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(input_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        output_cap = cv2.VideoWriter("output_video.mp4", fourcc, fps, (width, height))

        # Font settings for displaying FPS
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 1
        font_color = (255, 255, 255)
        font_thickness = 2
        org = (10, 30)  # Position to display FPS in the top-left corner

        frame_count = 0
        start_time = time.time()
        fps_text = ""  # Initialize fps_text outside the loop

        while True:
            ret, frame = input_cap.read()
            if not ret:
                break

            # Preprocess the frame
            preprocessed_frame = preprocess_frame(frame)

            # Apply the dehazing model to the frame
            dehazed_frame = model.predict(preprocessed_frame)

            # Postprocess the dehazed frame
            final_frame = postprocess_frame(dehazed_frame[0], frame.shape)

            # Display the FPS on the frame
            frame_count += 1
            current_time = time.time()
            elapsed_time = current_time - start_time
            if elapsed_time >= 1.0:  # Update FPS every second
                fps_text = f"FPS: {frame_count / elapsed_time:.2f}"
                start_time = current_time
                frame_count = 0
            cv2.putText(final_frame, fps_text, org, font, font_scale, font_color, font_thickness, cv2.LINE_AA)

            # Display the dehazed frame
            self.update_video_display(frame, self.input_video_display)
            self.update_video_display(final_frame, self.output_video_display)

            # Write the dehazed frame to the output video
            output_cap.write(final_frame)

            # Allow the GUI to update
            QApplication.processEvents()

        # Release the video capture and writer
        input_cap.release()
        output_cap.release()



def main():
    app = QApplication(sys.argv)
    window = VideoProcessingApp()
    window.show()
    sys.exit(app.exec_())

if __name__ == "__main__":
    main()